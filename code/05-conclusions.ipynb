{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As the amount of training data increases, the classification model's accuracy sees diminishing returns. Both the logistic regression and Naive Bayes models demonstrated a similar, if not identical, increase in accuracy as the dataset size increased. As such I only evaluate the logistic regression model below.**  \n",
    "\n",
    "*Increase in model accuracy*  \n",
    "--> For each 1% increase in datapool size, the model's accuracy score increases by:  \n",
    "\n",
    "small -> medium = 0.00039  \n",
    "small -> large = 0.00026  \n",
    "medium -> large = 0.00023  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data science consultant applies these techniques to your projects to quantify the effect of gathering new data on the performance of your current and future models. Adding a data scientist to your team will minimize the cost of data acquisition and help your team build more effective models.  \n",
    "\n",
    "The data scientist is also knowledgable of statistical and sampling techniques that are used to maximize the value of preexisting data. One such method is bootstrapping, which allows the same set of data to be recycled (sampling with replacement) in order to increase the size of the training dataset. The data scientist will reccommend such techniques when appropriate.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of this demonstration\n",
    "## Dataset sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small: 3000  \n",
    "Medium: 5300  \n",
    "Large: 7491  \n",
    "\n",
    "Medium dataset has 77% more posts than the baseline.  \n",
    "Large dataset has 150% more posts than the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small dataset\n",
    "\n",
    "('Train:', 0.9266666666666666, 'Test:', 0.8373333333333334) \n",
    "\n",
    "Medium dataset\n",
    "\n",
    "('Train:', 0.9116981132075471, 'Test:', 0.8671698113207548) \n",
    "\n",
    "Large dataset\n",
    "\n",
    "('Train:', 0.9156283374866501, 'Test:', 0.8766684463427656)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes - Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small dataset\n",
    "\n",
    "('Train:', 0.8937777777777778, 'Test:', 0.8333333333333334) \n",
    "\n",
    "Medium dataset\n",
    "\n",
    "('Train:', 0.8925786163522013, 'Test:', 0.8641509433962264) \n",
    "\n",
    "Large dataset\n",
    "\n",
    "('Train:', 0.8948024207903168, 'Test:', 0.8750667378537106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00039\n"
     ]
    }
   ],
   "source": [
    "# From small to medium\n",
    "acc_increase = (medium_acc - small_acc)\n",
    "pct_increase_in_data = 100 * ((5300 / 3000) - 1)\n",
    "\n",
    "print(round(acc_increase / pct_increase_in_data, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00023\n"
     ]
    }
   ],
   "source": [
    "# From medium to large\n",
    "acc_increase = (large_acc - medium_acc)\n",
    "pct_increase_in_data = 100 * ((7491 / 5300) - 1)\n",
    "\n",
    "print(round(acc_increase / pct_increase_in_data, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00026\n"
     ]
    }
   ],
   "source": [
    "# From small to large\n",
    "acc_increase = (large_acc - small_acc)\n",
    "pct_increase_in_data = 100 * ((7491 / 3000) - 1)\n",
    "\n",
    "print(round(acc_increase / pct_increase_in_data, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
