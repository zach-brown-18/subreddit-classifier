{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "**Purpose**  \n",
    "Determine the best parameters for the models and test their performance as more training data is used.\n",
    "\n",
    "*High Level Approach*\n",
    " * Compute baseline accuracy for 3 datasets\n",
    " * Build logistic regression model using both cvec and tfidif\n",
    " * Build Multinomial Naive Bayes model using cvec\n",
    " * Build Gaussian Naive Bayes model using tfidif\n",
    " \n",
    "First we use only text data and grid search to find best params.  \n",
    "Then we fit a model using these params and all data, both text and numerical.  \n",
    "\n",
    "*Why these models?*  \n",
    "\n",
    "Logistic Regression and Naive Bayes are industry standards for binary classification problems. The Logistic Regression model is best suited to this demonstration becuase it demonstrates strong performance, fast run times, and can handle float and negative data values. The Naive Bayes model is limited to handling the vectorized text data. It is also slower to fit to the training data. Hence, Logistic Regression is the clear choice of production models here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Credit:** This notebook borrows heavily from Noah's 5.02 lab review. Particularly the logistic regression grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import text as text_sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin # this allows us to create a custom transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final list of stopwords\n",
    "web_link_stop_words = ['amp', 'webp', 'www', 'https', 'http', 'png', 'pjpg', 'com']\n",
    "reddit_stop_words = ['reddit', 'poll', 'redd']\n",
    "bland_bigrams_stop_words = ['hope', 'enjoy']\n",
    "\n",
    "custom_stop_words = text_sk.ENGLISH_STOP_WORDS.union(web_link_stop_words).union(reddit_stop_words).union(bland_bigrams_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "small = pd.read_csv('../data/clean/small.csv')\n",
    "medium = pd.read_csv('../data/clean/medium.csv')\n",
    "large = pd.read_csv('../data/clean/large.csv')\n",
    "\n",
    "data = [small, medium, large]\n",
    "data_dict = {'small':small, 'medium':medium, 'large':large}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use text data for gridsearching\n",
    "X_all = [df['all_text'] for df in data]\n",
    "y_all = [df['subreddit'] for df in data]\n",
    "\n",
    "X_dict_all = {size:val['all_text'] for size,val in data_dict.items()}\n",
    "y_dict_all = {size:val['subreddit'] for size,val in data_dict.items()}\n",
    "\n",
    "# Keys = ['s', 'm', 'l'] and values = [X_train, X_test, y_train, y_test]\n",
    "split_all = {X_dict[0]:train_test_split(X_dict[1], y, stratify=y, random_state=18) for X_dict,y in zip(X_dict_all.items(), y_all)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'small': 0.6, 'medium': 0.5471698113207547, 'large': 0.5461825947677522}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_scores = {size:max(splits[3].value_counts(normalize=True)) for size,splits in split_all.items()}\n",
    "baseline_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Baseline models performs with 60%, 54.7%, and 54.6% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - CountVectorizer & TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('tf', TfidfTransformer()),\n",
    "    ('lr', LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'cv__max_features': [1500, 2500, 3500],\n",
    "    'cv__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "    'cv__stop_words'  : [custom_stop_words],\n",
    "    'tf__use_idf': [True, False] # if True, acts like TFIDF, if False, acts like CountVectorizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.892 Test: 0.832\n",
      "Train: 0.9134591194968553 Test: 0.8633962264150944\n",
      "Train: 0.9200783196867213 Test: 0.8814735718099306\n",
      "CPU times: user 6.09 s, sys: 363 ms, total: 6.45 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for size,split in split_all.items():\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split\n",
    "\n",
    "    gs = GridSearchCV(pipe, param_grid= pipe_params, cv = 5,\n",
    "                      scoring = 'accuracy', n_jobs = 7)\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Log scores and params\n",
    "    scores[size] = [gs.score(X_train, y_train), gs.score(X_test, y_test)]\n",
    "    params[size] = gs.best_params_\n",
    "    \n",
    "    if 'reddit' in params[size]['cv__stop_words']:\n",
    "        params[size]['cv__stop_words'] = 'custom_stop_words'\n",
    "\n",
    "    print('Train:', gs.score(X_train, y_train), 'Test:', gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Fast and yields the highest testing scores. The model is, however, overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'small': {'cv__max_features': 1500,\n",
       "  'cv__ngram_range': (1, 1),\n",
       "  'cv__stop_words': 'custom_stop_words',\n",
       "  'tf__use_idf': False},\n",
       " 'medium': {'cv__max_features': 2500,\n",
       "  'cv__ngram_range': (1, 2),\n",
       "  'cv__stop_words': 'custom_stop_words',\n",
       "  'tf__use_idf': True},\n",
       " 'large': {'cv__max_features': 3500,\n",
       "  'cv__ngram_range': (1, 3),\n",
       "  'cv__stop_words': 'custom_stop_words',\n",
       "  'tf__use_idf': True}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer with MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mnnb = {}\n",
    "params_mnnb = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params = {'vectorizer__max_features': [1500, 2500, 3500, 4500],\n",
    "               'vectorizer__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "               'vectorizer__stop_words': ['english', custom_stop_words],\n",
    "               'mnb__alpha': np.linspace(2.5,4,5)\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8937777777777778 Test: 0.8333333333333334\n",
      "Train: 0.8925786163522013 Test: 0.8641509433962264\n",
      "Train: 0.8948024207903168 Test: 0.8750667378537106\n",
      "CPU times: user 19.5 s, sys: 1.6 s, total: 21.1 s\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for size,split in split_all.items():\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split\n",
    "\n",
    "    gs_cv_mnb = GridSearchCV(pipe,\n",
    "                             param_grid = pipe_params,\n",
    "                             n_jobs = 7,\n",
    "                             cv = 5,\n",
    "                             scoring = 'accuracy')\n",
    "\n",
    "    gs_cv_mnb.fit(X_train, y_train)\n",
    "\n",
    "    # Log scores and params\n",
    "    scores_mnnb[size] = [gs_cv_mnb.score(X_train, y_train), gs_cv_mnb.score(X_test, y_test)]\n",
    "    params_mnnb[size] = gs_cv_mnb.best_params_\n",
    "    \n",
    "    if 'reddit' in params_mnnb[size]['vectorizer__stop_words']:\n",
    "        params_mnnb[size]['vectorizer__stop_words'] = 'custom_stop_words'\n",
    "\n",
    "    print('Train:', gs_cv_mnb.score(X_train, y_train), 'Test:', gs_cv_mnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Training scores remain similar as the sample size increases. Testing scores approach the train score as the sample size increases. Model trains slower than the logistic regression and performs with approximately equal accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'small': {'mnb__alpha': 3.625,\n",
       "  'vectorizer__max_features': 4500,\n",
       "  'vectorizer__ngram_range': (1, 1),\n",
       "  'vectorizer__stop_words': 'english'},\n",
       " 'medium': {'mnb__alpha': 2.5,\n",
       "  'vectorizer__max_features': 4500,\n",
       "  'vectorizer__ngram_range': (1, 1),\n",
       "  'vectorizer__stop_words': 'english'},\n",
       " 'large': {'mnb__alpha': 2.875,\n",
       "  'vectorizer__max_features': 4500,\n",
       "  'vectorizer__ngram_range': (1, 1),\n",
       "  'vectorizer__stop_words': 'english'}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_mnnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDFVectorizer with GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gnb = {}\n",
    "params_gnb = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    (\"_\", DenseTransformer()),\n",
    "    ('gnb', GaussianNB())\n",
    "])\n",
    "\n",
    "pipe_params = {'vectorizer__max_features': [1500, 2500, 3500],\n",
    "               'vectorizer__ngram_range'  : [(1,1), (1,2), (1,3)],\n",
    "               'vectorizer__stop_words': ['english', custom_stop_words]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9297777777777778 Test: 0.7653333333333333\n",
      "Train: 0.8759748427672956 Test: 0.7984905660377358\n",
      "Train: 0.914560341758633 Test: 0.8152696209289909\n",
      "CPU times: user 7.58 s, sys: 1.47 s, total: 9.04 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for size,split in split_all.items():\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split\n",
    "    \n",
    "    gs = GridSearchCV(pipe,\n",
    "                      param_grid = pipe_params,\n",
    "                      n_jobs = 7,\n",
    "                      cv = 5,\n",
    "                      scoring = 'accuracy')\n",
    "\n",
    "    gs_tfidf = gs.fit(X_train, y_train)\n",
    "    \n",
    "    scores_gnb[size] = [gs_tfidf.score(X_train, y_train), gs_tfidf.score(X_test, y_test)]\n",
    "    params_gnb[size] = gs_tfidf.best_params_\n",
    "    \n",
    "    if 'reddit' in params_gnb[size]['vectorizer__stop_words']:\n",
    "        params_gnb[size]['vectorizer__stop_words'] = 'custom_stop_words'\n",
    "\n",
    "    print('Train:', gs_tfidf.score(X_train, y_train), 'Test:', gs_tfidf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation:** Tfidf Vectorizer and Gaussian NB massively overfits to the training data. Abandon this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'small': {'vectorizer__max_features': 3500,\n",
       "  'vectorizer__ngram_range': (1, 3),\n",
       "  'vectorizer__stop_words': 'custom_stop_words'},\n",
       " 'medium': {'vectorizer__max_features': 1500,\n",
       "  'vectorizer__ngram_range': (1, 2),\n",
       "  'vectorizer__stop_words': 'english'},\n",
       " 'large': {'vectorizer__max_features': 3500,\n",
       "  'vectorizer__ngram_range': (1, 3),\n",
       "  'vectorizer__stop_words': 'english'}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_gnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Fit Final Models\n",
    "Using text and numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X_all = [df.drop(columns=['subreddit']) for df in data]\n",
    "y_all = [df['subreddit'] for df in data]\n",
    "\n",
    "# Dictionaries\n",
    "X_dict_all = {size:val.drop(columns='subreddit') for size,val in data_dict.items()}\n",
    "y_dict_all = {size:val['subreddit'] for size,val in data_dict.items()}\n",
    "\n",
    "# Keys = ['small', 'medium', 'large'] and values = [X_train, X_test, y_train, y_test]\n",
    "split_all = {X_dict[0]:train_test_split(X_dict[1], y, stratify=y, random_state=18) for X_dict,y in zip(X_dict_all.items(), y_all)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part was tricky. Here's what I did:  \n",
    "1. Transformed the text data using best params found in above gridsearching.\n",
    "2. Merged with number data.\n",
    "3. Fit the model and scored it using the accuracy metric.  \n",
    "4. Didn't work with Naive Bayes Multinomial. Probably broke the multinomial distribution assumption. Resolved by fitting on text data only.\n",
    "\n",
    "I will figure out a better way using ColumnTransformer before adding this to my portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_custom(train, test, transformer):\n",
    "        vec = transformer\n",
    "        vec.fit(train['all_text'])\n",
    "        \n",
    "        v_train = vec.transform(train['all_text'])\n",
    "        v_test = vec.transform(test['all_text'])\n",
    "\n",
    "        v_train = pd.DataFrame(v_train.todense(), columns=vec.get_feature_names()).reset_index(drop=True)\n",
    "        v_test = pd.DataFrame(v_test.todense(), columns=vec.get_feature_names()).reset_index(drop=True)\n",
    "        \n",
    "        return v_train, v_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_combine(data_size, tfidf=False, stopwords=custom_stop_words, max_features=1500, ngram_range=(1,1)):\n",
    "    X_train, X_test, y_train, y_test = split_all[data_size]\n",
    "\n",
    "    if tfidf:\n",
    "        tfidf = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range, stop_words=stopwords)\n",
    "        v_train, v_test = fit_transform_custom(X_train, X_test, tfidf)\n",
    "    \n",
    "    else:\n",
    "        cv = CountVectorizer(max_features=max_features, ngram_range=ngram_range, stop_words=stopwords)\n",
    "        v_train, v_test = fit_transform_custom(X_train, X_test, cv)\n",
    "\n",
    "    num_data_train = X_train.drop(columns='all_text').reset_index(drop=True)\n",
    "    num_data_test = X_test.drop(columns='all_text').reset_index(drop=True)\n",
    "\n",
    "    together_train = pd.concat([v_train,num_data_train], axis=1)\n",
    "    together_test = pd.concat([v_test,num_data_test], axis=1)\n",
    "    \n",
    "    return together_train, together_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_show_log(X_train, X_test, y_train, y_test):\n",
    "    log_reg = LogisticRegression(solver = 'liblinear')\n",
    "    log_reg.fit(X_train, y_train);\n",
    "    return 'Train:', log_reg.score(X_train, y_train), 'Test:', log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small dataset\n",
      "\n",
      "('Train:', 0.9266666666666666, 'Test:', 0.8373333333333334) \n",
      "\n",
      "Medium dataset\n",
      "\n",
      "('Train:', 0.9116981132075471, 'Test:', 0.8671698113207548) \n",
      "\n",
      "Large dataset\n",
      "\n",
      "('Train:', 0.9156283374866501, 'Test:', 0.8766684463427656)\n"
     ]
    }
   ],
   "source": [
    "print('Small dataset\\n')\n",
    "print(fit_show_log(*vec_combine('small')), '\\n')\n",
    "\n",
    "print('Medium dataset\\n')\n",
    "print(fit_show_log(*vec_combine('medium', tfidf=True, max_features=2500, ngram_range=(1,2))), '\\n')\n",
    "\n",
    "print('Large dataset\\n')\n",
    "print(fit_show_log(*vec_combine('large', tfidf=True, max_features=3500, ngram_range=(1,3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_fit_nb(data_size, alpha):\n",
    "    X_train, X_test, y_train, y_test = split_all[data_size]\n",
    "    X_train, X_test = fit_transform_custom(X_train, X_test, CountVectorizer(max_features=4500, stop_words='english'))\n",
    "\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "    nb.fit(X_train, y_train);\n",
    "    return 'Train:', nb.score(X_train, y_train), 'Test:', nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small dataset\n",
      "\n",
      "('Train:', 0.8937777777777778, 'Test:', 0.8333333333333334) \n",
      "\n",
      "Medium dataset\n",
      "\n",
      "('Train:', 0.8925786163522013, 'Test:', 0.8641509433962264) \n",
      "\n",
      "Large dataset\n",
      "\n",
      "('Train:', 0.8948024207903168, 'Test:', 0.8750667378537106)\n"
     ]
    }
   ],
   "source": [
    "print('Small dataset\\n')\n",
    "print(transform_fit_nb('small', 3.625), '\\n')\n",
    "\n",
    "print('Medium dataset\\n')\n",
    "print(transform_fit_nb('medium', 2.5), '\\n')\n",
    "\n",
    "print('Large dataset\\n')\n",
    "print(transform_fit_nb('large', 2.875))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
